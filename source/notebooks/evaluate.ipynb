{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TdfEQ639WdQv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "f2474226-9e1e-4e4b-f32b-12ae56e94874",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556949573953E12,
     "user_tz": -420.0,
     "elapsed": 5967.0,
     "user": {
      "displayName": "Tri Nguyen Duc",
      "photoUrl": "",
      "userId": "07671390057893090774"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: naruto_skills in /usr/local/lib/python3.6/dist-packages (1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install naruto_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gdklphBbU9AK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/source/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vscJie6oU9Ab",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from model_def.baseline import Baseline\n",
    "from utils import pytorch_utils\n",
    "from data_for_train import my_dataset\n",
    "from train import trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h0ekwp_Vap1",
    "colab_type": "text"
   },
   "source": [
    "# Setup and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "69__hBkQU9Aj",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53.0
    },
    "outputId": "4b853914-9e7f-48f6-c8f4-cc4fd1da43bc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556949573982E12,
     "user_tz": -420.0,
     "elapsed": 5902.0,
     "user": {
      "displayName": "Tri Nguyen Duc",
      "photoUrl": "",
      "userId": "07671390057893090774"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Src vocab contains 3519 tokens\n",
      "INFO:root:Tgt vocab contains 8758 tokens\n"
     ]
    }
   ],
   "source": [
    "my_dataset.bootstrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qiV1t6tdU9A0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376.0
    },
    "outputId": "593cfacc-81dd-4216-e95a-b7e3bc07bd36",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556949578264E12,
     "user_tz": -420.0,
     "elapsed": 10166.0,
     "user": {
      "displayName": "Tri Nguyen Duc",
      "photoUrl": "",
      "userId": "07671390057893090774"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load pre-trained model from /source/main/train/output/saved_models/Baseline/2019-05-04T01:16:45/180000.pt successfully\n",
      "INFO:root:Model architecture: \n",
      "Baseline(\n",
      "  (input_embedding): Embedding(3519, 512)\n",
      "  (conv1): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.3)\n",
      "  (conv4): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv4_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv5_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv6_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=256, out_features=8758, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:root:Total trainable parameters: 9104438\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# del model\n",
    "model = Baseline(src_word_vocab_size=len(my_dataset.voc_src.index2word),\n",
    "                     tgt_word_vocab_size=len(my_dataset.voc_tgt.index2word))\n",
    "model.to(device)\n",
    "PRE_TRAINED_MODEL='/source/main/train/output/saved_models/Baseline/2019-05-04T01:16:45/180000.pt'\n",
    "checkpoint = torch.load(PRE_TRAINED_MODEL, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "logging.info('Load pre-trained model from %s successfully', PRE_TRAINED_MODEL)\n",
    "\n",
    "model.eval()\n",
    "logging.info('Model architecture: \\n%s', model)\n",
    "logging.info('Total trainable parameters: %s', pytorch_utils.count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "FC2HZXZaU9A9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GJNo9dSfU9BC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def docs2input_tensors(preprocessed_docs, device):\n",
    "    seq_len = [len(doc.split()) for doc in preprocessed_docs]\n",
    "    word_input = [my_dataset.voc_src.docs2idx([doc], equal_length=MAX_LEN)[0] for doc in preprocessed_docs]\n",
    "    \n",
    "    inputs = (word_input, seq_len)\n",
    "    inputs = [np.array(i) for i in inputs]\n",
    "    input_tensors = [torch.from_numpy(i) for i in inputs]\n",
    "    input_tensors = [i.to(device) for i in input_tensors]\n",
    "    return input_tensors\n",
    "\n",
    "def replace_unk_tok(pred, src):\n",
    "    pred = [p if p!='¶' else s for p, s in zip(pred.split(), src.split())]\n",
    "    return ' '.join(pred)\n",
    "\n",
    "def predict_batch(docs):\n",
    "    input_tensors = docs2input_tensors(docs, device)\n",
    "    predict_tensor = model.cvt_output(model(*input_tensors))\n",
    "    predict_numpy = predict_tensor.cpu().numpy()\n",
    "    \n",
    "    translated_docs = my_dataset.voc_tgt.idx2docs(predict_numpy)\n",
    "    translated_docs = [' '.join(pred_doc.split()[:len(src_doc.split())]) \n",
    "                       for src_doc, pred_doc in zip(docs, translated_docs)]\n",
    "    translated_docs = [replace_unk_tok(pred, src) for pred, src in zip(translated_docs, docs)]\n",
    "    return translated_docs\n",
    "\n",
    "def predict_docs(docs, batch_size):\n",
    "    return list(chain(*[predict_batch(docs[i: i+batch_size]) for i in range(0, len(docs), batch_size)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t8nzk33zU9BL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "0a482718-c568-437b-c074-31e4e50018fa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556949578296E12,
     "user_tz": -420.0,
     "elapsed": 10138.0,
     "user": {
      "displayName": "Tri Nguyen Duc",
      "photoUrl": "",
      "userId": "07671390057893090774"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hôm nay tôi đi học karetoal']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_docs(['hom nay toi di hoc karetoal'], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3oTk8d4qU9BU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def get_metrics(df):\n",
    "    logging.info('Total sentences: %s', df.shape[0])\n",
    "    sen_acc = (df['tgt'] == df['pred']).sum()/df.shape[0]\n",
    "    \n",
    "    df = df[df['tgt'].map(lambda x: len(x.split())) == df['pred'].map(lambda x: len(x.split()))]\n",
    "    logging.info('Total predicted sequences without changing len: %s', df.shape[0])\n",
    "    tok_tgt = [tok for doc in df['tgt'] for tok in doc.split()]\n",
    "    tok_pred = [tok for doc in df['pred'] for tok in doc.split()]\n",
    "    sen_tok = (np.array(tok_tgt) == np.array(tok_pred)).sum()/len(tok_tgt)\n",
    "    \n",
    "    return sen_acc, sen_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmUk0RjbU9Bi",
    "colab_type": "text"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5ba0p1uIU9Bl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/source/main/data_for_train/output/my_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sRBVboKtU9Bz",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "outputId": "5d51e981-a033-4592-b8eb-2f9cca440393",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556949581543E12,
     "user_tz": -420.0,
     "elapsed": 13325.0,
     "user": {
      "displayName": "Tri Nguyen Duc",
      "photoUrl": "",
      "userId": "07671390057893090774"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Duration: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pred = predict_docs(list(df['src']), batch_size=128)\n",
    "end = time.time()\n",
    "df['pred'] = pred\n",
    "logging.info('Duration: %.2f s' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RAVAVztIU9B9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71.0
    },
    "outputId": "c6ca7017-ffd7-4ab3-ce49-eb8cf8c105d3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556949581558E12,
     "user_tz": -420.0,
     "elapsed": 13309.0,
     "user": {
      "displayName": "Tri Nguyen Duc",
      "photoUrl": "",
      "userId": "07671390057893090774"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Total sentences: 5000\n",
      "INFO:root:Total predicted sequences without changing len: 5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3934, 0.9739834829348896)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0Fr5OFkYYbm",
    "colab_type": "text"
   },
   "source": [
    "- Baseline/2019-05-04T01:16:45:\n",
    "  + 150k: 0.383, 0.9732856714953901\n",
    "  + 180k: 0.3934, 0.9739834829348896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "2QsM__iwa5Fv",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "evaluate.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
